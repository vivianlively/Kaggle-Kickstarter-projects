{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression-NN-Pecep-Ada-Bagging-Gradient.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E-SFqSoJ3Zqa"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "#2. Get the file   \n",
        "downloaded = drive.CreateFile({'id':'15m4e1JbUncRhKmPj8YfrBIefJKBVcUCZ'}) \n",
        "#file name\n",
        "downloaded.GetContentFile('ks-projects-201801.csv') \n",
        "\n",
        "downloaded = drive.CreateFile({'id':'1ROXl1B5202_Z0xs56gfblIg7CjrKlnIZ'}) \n",
        "#file name\n",
        "downloaded.GetContentFile('test_one_hot_70.csv') \n",
        "\n",
        "downloaded = drive.CreateFile({'id':'1cmJYNnfd0IYBk3U9sLsRjVSz3ihvlsRI'}) \n",
        "#file name\n",
        "downloaded.GetContentFile('train_one_hot_70.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "import time\n",
        "# import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "TOY_DATA_PATH = \"../toy.csv\"\n",
        "DATA_PATH = \"ks-projects-201801.csv\"\n",
        "PROCESSED_TOY_DATA_PATH = \"../toy_processed.csv\"\n",
        "\n",
        "PROCESSED_TRAIN_PATH = \"../data/train.csv\"\n",
        "PROCESSED_TEST_PATH = \"../data/test.csv\"\n",
        "\n",
        "PROCESSED80_TRAIN_PATH = \"../data/train_80.csv\"\n",
        "PROCESSED80_TEST_PATH = \"../data/test_80.csv\"\n",
        "\n",
        "PROCESSED95_TRAIN_PATH = \"../data/train_95.csv\"\n",
        "PROCESSED95_TEST_PATH = \"../data/test_95.csv\"\n",
        "\n",
        "PROCESSED99_TRAIN_PATH = \"../data/train_99.csv\"\n",
        "PROCESSED99_TEST_PATH = \"../data/test_99.csv\"\n",
        "\n",
        "STANDARDIZED_TRAIN_PATH = \"../data/train_standardized.csv\"\n",
        "STANDARDIZED_TEST_PATH = \"../data/test_standardized.csv\"\n",
        "\n",
        "SCALED_TRAIN_PATH = \"../data/train_scaled.csv\"\n",
        "SCALED_TEST_PATH = \"../data/test_scaled.csv\"\n",
        "\n",
        "ONE_HOT_TRAIN_PATH_70 = \"train_one_hot_70.csv\"\n",
        "ONE_HOT_TEST_PATH_70 = \"test_one_hot_70.csv\"\n",
        "\n",
        "ONE_HOT_TRAIN_PATH_80 = \"../data/train_one_hot_80.csv\"\n",
        "ONE_HOT_TEST_PATH_80 = \"../data/test_one_hot_80.csv\"\n",
        "\n",
        "FEATURES = ['main_category', 'backers', 'country', 'usd_goal_real', 'duration_in_days']\n",
        "FEATURES_TO_PLOT = [\"main_category\", \"country\", \"state\"]\n",
        "FEATURES_TO_DROP = ['ID', 'name', 'category', 'currency', 'goal', 'pledged', 'usd pledged', 'usd_pledged_real']\n",
        "FEATURES_TO_ENCODE = [\"main_category\", \"country\"]\n",
        "FEATURES_TO_STANDARDIZE = ['backers', 'usd_goal_real', 'duration_in_days']\n",
        "\n",
        "class TransformMode(enum.Enum):\n",
        "   NONE = 0\n",
        "    # Whether to standardize columns in FEATURES_TO_STANDARDIZE\n",
        "   STANDARDIZE_SELECTED_COLUMNS = 1\n",
        "    # Whether to scale all FEATURES, final range (0,20)\n",
        "   SCALE_WITH_RANGE = 2\n",
        "    # Only scale 'backers', 'usd_goal_real', 'duration_in_days', using default range\n",
        "   SCALE_SELECTED_COLUMNS = 3\n",
        "\n",
        "MODE = TransformMode.NONE\n",
        "\n",
        "'''\n",
        "    Steps:\n",
        "    1) Drop unnecessary features\n",
        "    2) Drop rows whose 'state' is not in (\"successful\", \"failed\")\n",
        "    3) Create a new feature 'duration_in_days' based on the difference between deadline and launched date\n",
        "    4) One-hot encode categorical data ('main_category' and 'country'), convert 'state' column from String to Integer (1 or 0)\n",
        "    5) (Skipped) Standardize numerical columns ('backers', 'usd_goal_real', 'duration_in_days')\n",
        "    6) Randomize/shuffle，and split into train/test set with a ratio of 9:1 (or 7:3, 8:2)\n",
        "'''\n",
        "def pre_process():\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    #examine_data(df)\n",
        "    #plot_with_pie_chart(df)\n",
        "    #plot_target_categories(df)\n",
        "\n",
        "    # Drop the features that are not needed\n",
        "    drop_features(df)\n",
        "    # print(\" --- number of rows before = {}\".format(len(df)))\n",
        "    df = drop_rows(df)\n",
        "    # print(\" --- number of rows after = {}\".format(len(df)))\n",
        "    df = encode_columns(df)\n",
        "\n",
        "    # Create a new column \"duration_in_days\" by calculating\n",
        "    # the number of days difference between \"deadline\" and \"launched\"\n",
        "    convert_duration_fast(df)\n",
        "\n",
        "    if MODE == TransformMode.STANDARDIZE_SELECTED_COLUMNS:\n",
        "        standardize(df)\n",
        "    elif MODE == TransformMode.SCALE_WITH_RANGE:\n",
        "        scale(df)\n",
        "    elif MODE == TransformMode.SCALE_SELECTED_COLUMNS:\n",
        "        scale_selected_features(df)\n",
        "\n",
        "    # split data into 70% training set, 30% test set\n",
        "    train_set, test_set = shuffle_and_split(df, 0.3)\n",
        "    examine_data(df)\n",
        "\n",
        "    # df.to_csv(PROCESSED_TOY_DATA_PATH, index=False)\n",
        "\n",
        "    if MODE == TransformMode.STANDARDIZE_SELECTED_COLUMNS:\n",
        "        train_set.to_csv(STANDARDIZED_TRAIN_PATH, index=False)\n",
        "        test_set.to_csv(STANDARDIZED_TEST_PATH, index=False)\n",
        "    elif MODE == TransformMode.SCALE_WITH_RANGE or MODE == TransformMode.SCALE_SELECTED_COLUMNS:\n",
        "        train_set.to_csv(SCALED_TRAIN_PATH, index=False)\n",
        "        test_set.to_csv(SCALED_TEST_PATH, index=False)\n",
        "    else:\n",
        "        #train_set.to_csv(PROCESSED_TRAIN_PATH, index=False)\n",
        "        #test_set.to_csv(PROCESSED_TEST_PATH, index=False)\n",
        "        train_set.to_csv(ONE_HOT_TRAIN_PATH_70, index=False)\n",
        "        test_set.to_csv(ONE_HOT_TEST_PATH_70, index=False)\n",
        "\n",
        "# Plot the y column using a Seaborn countplot\n",
        "def plot_target_categories(df):\n",
        "    sns.countplot(x=\"state\", data=df, palette='hls')\n",
        "    plt.xlabel(\"Funding Status\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.title(\"Count of Funding Outcome\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_with_pie_chart(df):\n",
        "    '''\n",
        "    Categorical data has a categories and a ordered property, which list their possible values\n",
        "    and whether the ordering matters or not. These properties are exposed as s.cat.categories and s.cat.ordered.\n",
        "    If you don’t manually specify categories and ordering, they are inferred from the passed arguments.\n",
        "    '''\n",
        "    for feature in FEATURES_TO_PLOT:\n",
        "        labels = df[feature].astype('category').cat.categories.tolist()\n",
        "        counts = df[feature].value_counts()\n",
        "        sizes = [counts[var_cat] for var_cat in labels]\n",
        "        fig1, ax1 = plt.subplots()\n",
        "        ax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True)  # autopct is show the % on plot\n",
        "        ax1.axis('equal')\n",
        "        #plt.title(\"Feature Distribution - \" + str(feature))\n",
        "        ax1.set_title(\"Feature Distribution - \" + str(feature), pad=20)\n",
        "        plt.show()\n",
        "\n",
        "def examine_data(df):\n",
        "    print(\"\\n ------ Examining data... ------\")\n",
        "    print(df.shape)\n",
        "    #print(df.info())\n",
        "    #print(\"List of attributes: \", list(df.columns))\n",
        "    #print(\"Total number of attributes: \", len(list(df.columns))-1)\n",
        "\n",
        "    '''\n",
        "    backers: min=0, max=219382\n",
        "    usd_goal_real: min=0.01, max=166361390.71\n",
        "    duration_in_days: min=0, max=91\n",
        "    \n",
        "    for feature in FEATURES_TO_STANDARDIZE:\n",
        "        print(\"{}: min={}, max={}\".format(feature, df[feature].min(), df[feature].max()))\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    # Print number of null values (3801 in total)\n",
        "    print(\"Number of null values={}\".format(df.isnull().values.sum()))\n",
        "    \n",
        "    # Column-wise distribution of null values\n",
        "    # The result shows there are 4 null values in 'name' column, \n",
        "    # and 3797 in 'usd pledged' column\n",
        "    # no need to worry since I don't use these 2 columns anyway\n",
        "    print(df.isnull().sum())\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    # print a table of main_category : count\n",
        "    # Total categories = 15\n",
        "    print(df['main_category'].value_counts())\n",
        "    # two ways to get the number of unique values in main_category\n",
        "    print(df['main_category'].value_counts().count())\n",
        "    print(\"Number of unique project categories = {}\".format(df['main_category'].nunique()))\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    # Total defined countries: 22.\n",
        "    # The only undefined countries \"N,0\" will occur with state = \"undefined\", and it's dropped already\n",
        "    print(df['country'].value_counts())\n",
        "    print(df['country'].value_counts().count())\n",
        "    '''\n",
        "\n",
        "    print(\"backers: mean={}, median={}, std={}\".format(df['backers'].mean(), df['backers'].median(), df['backers'].std()))\n",
        "    print(\"usd goal: mean={}, median={}, std={}\".format(df['usd_goal_real'].mean(), df['usd_goal_real'].median(), df['usd_goal_real'].std()))\n",
        "    print(\"duration in days: mean={}, median={}, std={}\".format(df['duration_in_days'].mean(), df['duration_in_days'].median(), df['duration_in_days'].std()))\n",
        "    print(\"------ Examination Done! ------\")\n",
        "\n",
        "def drop_features(df):\n",
        "    for feature in FEATURES_TO_DROP:\n",
        "        df.drop([feature], axis=1, inplace=True)\n",
        "\n",
        "# drop all rows whose |state| is not in (\"successful\", \"failed\")\n",
        "def drop_rows(df):\n",
        "    # df['state']:  (0, 'successful') (1, 'failed') (2, 'failed') (3, 'undefined') (4, 'canceled') ...\n",
        "    successRows = df[df['state'] == 'successful']\n",
        "    failedRows = df[df['state'] == 'failed']\n",
        "    tmp_df = pd.concat([successRows, failedRows])\n",
        "\n",
        "    # Filter out rows whose 'country' has an invalid value\n",
        "    return tmp_df[~tmp_df['country'].str.contains(\"N,0\")]\n",
        "    #validCountries = df[~df['country'].str.contains(\"N,0\")]\n",
        "    #return pd.concat([successRows, failedRows])\n",
        "\n",
        "def encode_columns(df):\n",
        "    # There are 15 categories in total\n",
        "    # 22 countries in total (excluding the one country that's invalid - N,0)\n",
        "    '''\n",
        "    encoder = LabelEncoder()\n",
        "    for feature in FEATURES_TO_ENCODE:\n",
        "        df[feature] = encoder.fit_transform(df[feature])\n",
        "\n",
        "    '''\n",
        "    # one-hot encode 'country' column\n",
        "    country_one_hot = pd.get_dummies(df.country, prefix='is_country_')\n",
        "    df.drop(['country'], axis=1, inplace=True)\n",
        "    df = pd.concat([df, country_one_hot], axis=1)\n",
        "\n",
        "    # one-hot encode 'main_category' column\n",
        "    category_one_hot = pd.get_dummies(df.main_category, prefix='is_category_')\n",
        "    df.drop(['main_category'], axis=1, inplace=True)\n",
        "    df = pd.concat([df, category_one_hot], axis=1)\n",
        "\n",
        "    # Convert state: 'successful' to 1, 'failed' to 0\n",
        "    df['state'] = df['state'].astype(str)\n",
        "    df['state'] = np.where(df[\"state\"].str.contains(\"successful\"), 1, 0)\n",
        "    print(\"Encoding done!!!\")\n",
        "    print(df.head())\n",
        "    return df\n",
        "\n",
        "'''\n",
        "# The original slow version. DO NOT USE!!!\n",
        "def convert_duration(df):\n",
        "    days = []\n",
        "    for index, row in df.iterrows():\n",
        "        startDate = str(row['launched']).split()[0]\n",
        "        endDate = str(row['deadline'])\n",
        "        start = datetime.datetime.strptime(startDate, \"%Y-%m-%d\").date()\n",
        "        end = datetime.datetime.strptime(endDate, \"%Y-%m-%d\").date()\n",
        "        duration = (end-start).days\n",
        "        days.append(duration)\n",
        "        # print(\"startDate={}, endDate={}, days={}\".format(startDate, endDate, duration))\n",
        "        print(\"idx={}, deadline={}, launched={}\".format(index, row['deadline'], row['launched']))\n",
        "    # add the new feature\n",
        "    df['duration_in_days'] = days\n",
        "\n",
        "    df.drop(['launched'], axis=1, inplace=True)\n",
        "    df.drop(['deadline'], axis=1, inplace=True)\n",
        "'''\n",
        "\n",
        "def convert_duration_fast(df):\n",
        "    df['launched'] = pd.to_datetime(df['launched'])\n",
        "    df['deadline'] = pd.to_datetime(df['deadline'])\n",
        "    df['duration_in_days'] = (df['deadline'] - df['launched']).dt.days\n",
        "\n",
        "    df.drop(['launched'], axis=1, inplace=True)\n",
        "    df.drop(['deadline'], axis=1, inplace=True)\n",
        "\n",
        "def standardize(df):\n",
        "    # df[FEATURES_TO_TRANSFORM] = df[FEATURES_TO_TRANSFORM].apply(lambda x: StandardScaler().fit_transform(x))\n",
        "    features = df[FEATURES_TO_STANDARDIZE]\n",
        "    scaler = StandardScaler().fit(features.values)\n",
        "    features = scaler.transform(features.values)\n",
        "    df[FEATURES_TO_STANDARDIZE] = features\n",
        "\n",
        "def scale(df):\n",
        "    features = df[FEATURES]\n",
        "    scaler = MinMaxScaler(feature_range=(0, 20)).fit(features.values)\n",
        "    features = scaler.transform(features.values)\n",
        "\n",
        "    df[FEATURES] = features\n",
        "\n",
        "def scale_selected_features(df):\n",
        "    features = df[['backers', 'usd_goal_real', 'duration_in_days']]\n",
        "    scaler = MinMaxScaler().fit(features.values)\n",
        "    features = scaler.transform(features.values)\n",
        "\n",
        "    df[['backers', 'usd_goal_real', 'duration_in_days']] = features\n",
        "\n",
        "# Adapted from page 52 of the book\n",
        "# Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow (2nd Edition)\n",
        "# Total rows: 331675\n",
        "def shuffle_and_split(data, test_ratio):\n",
        "    size = len(data)\n",
        "    shuffled_indices = np.random.permutation(size)\n",
        "    test_set_size = int(size * test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices], data.iloc[test_indices]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "    pre_process()\n",
        "    end_time = time.time()\n",
        "    print(\"Time taken: {}\".format(end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJYmlv8KtRfL",
        "outputId": "5c6b077c-3d56-40ef-fb56-2b71302bd172"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding done!!!\n",
            "      deadline             launched  state  backers  usd_goal_real  \\\n",
            "5   2016-04-01  2016-02-26 13:38:27      1      224       50000.00   \n",
            "6   2014-12-21  2014-12-01 18:30:44      1       16        1000.00   \n",
            "11  2013-04-08  2013-03-09 06:42:58      1      100       12500.00   \n",
            "14  2017-05-03  2017-04-05 19:44:18      1      761        6469.73   \n",
            "18  2012-08-17  2012-08-02 14:11:32      1        7         250.00   \n",
            "\n",
            "    is_country__AT  is_country__AU  is_country__BE  is_country__CA  \\\n",
            "5                0               0               0               0   \n",
            "6                0               0               0               0   \n",
            "11               0               0               0               0   \n",
            "14               0               0               0               0   \n",
            "18               0               0               0               0   \n",
            "\n",
            "    is_country__CH  ...  is_category__Fashion  is_category__Film & Video  \\\n",
            "5                0  ...                     0                          0   \n",
            "6                0  ...                     0                          0   \n",
            "11               0  ...                     0                          0   \n",
            "14               0  ...                     0                          0   \n",
            "18               0  ...                     0                          0   \n",
            "\n",
            "    is_category__Food  is_category__Games  is_category__Journalism  \\\n",
            "5                   1                   0                        0   \n",
            "6                   1                   0                        0   \n",
            "11                  0                   0                        0   \n",
            "14                  0                   1                        0   \n",
            "18                  0                   0                        0   \n",
            "\n",
            "    is_category__Music  is_category__Photography  is_category__Publishing  \\\n",
            "5                    0                         0                        0   \n",
            "6                    0                         0                        0   \n",
            "11                   1                         0                        0   \n",
            "14                   0                         0                        0   \n",
            "18                   1                         0                        0   \n",
            "\n",
            "    is_category__Technology  is_category__Theater  \n",
            "5                         0                     0  \n",
            "6                         0                     0  \n",
            "11                        0                     0  \n",
            "14                        0                     0  \n",
            "18                        0                     0  \n",
            "\n",
            "[5 rows x 42 columns]\n",
            "\n",
            " ------ Examining data... ------\n",
            "(331465, 41)\n",
            "backers: mean=116.45531504080371, median=15.0, std=965.7285980848495\n",
            "usd goal: mean=41523.19827535329, median=5000.0, std=1109273.733646225\n",
            "duration in days: mean=32.95595010031225, median=29.0, std=12.714113626590146\n",
            "------ Examination Done! ------\n",
            "Time taken: 11.747474908828735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression"
      ],
      "metadata": {
        "id": "124le8O1MJaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from io import StringIO\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.utils.fixes import loguniform\n",
        "\n",
        "\n",
        "TRAIN_DATA_PATH = \"../data/train.csv\"\n",
        "TEST_DATA_PATH = \"../data/test.csv\"\n",
        "\n",
        "TRAIN80_DATA_PATH = \"../data/train_80.csv\"\n",
        "TEST80_DATA_PATH = \"../data/test_80.csv\"\n",
        "\n",
        "TRAIN95_DATA_PATH = \"../data/train_95.csv\"\n",
        "TEST95_DATA_PATH = \"../data/test_95.csv\"\n",
        "\n",
        "TRAIN99_DATA_PATH = \"../data/train_99.csv\"\n",
        "TEST99_DATA_PATH = \"../data/test_99.csv\"\n",
        "\n",
        "ONE_HOT_TRAIN_PATH_70 = \"train_one_hot_70.csv\"\n",
        "ONE_HOT_TEST_PATH_70 = \"test_one_hot_70.csv\"\n",
        "\n",
        "STANDARDIZED_TRAIN_DATA_PATH = \"../train_standardized.csv\"\n",
        "STANDARDIZED_TEST_DATA_PATH = \"../test_standardized.csv\"\n",
        "\n",
        "SCALED_TRAIN_DATA_PATH = \"../data/train_scaled.csv\"\n",
        "SCALED_TEST_DATA_PATH = \"../data/test_scaled.csv\"\n",
        "\n",
        "FEATURES = ['main_category', 'backers', 'country', 'usd_goal_real', 'duration_in_days']\n",
        "#FEATURES_INDICES = [0,2,3,4,5]\n",
        "FEATURES_INDICES = list(range(1,41))\n",
        "\n",
        "class TransformMode(enum.Enum):\n",
        "   NONE = 0\n",
        "    # Whether to standardize columns in FEATURES_TO_STANDARDIZE\n",
        "   STANDARDIZE_SELECTED_COLUMNS = 1\n",
        "    # Whether to scale all FEATURES, final range (0,20)\n",
        "   SCALE_WITH_RANGE = 2\n",
        "    # Only scale 'backers', 'usd_goal_real', 'duration_in_days', using default range\n",
        "   SCALE_SELECTED_COLUMNS = 3\n",
        "\n",
        "MODE = TransformMode.NONE\n",
        "\n",
        "\n",
        "def logistic_regression(train_data, test_data):\n",
        "    train_y = train_data['state']\n",
        "    train_X = train_data.iloc[:, FEATURES_INDICES]\n",
        "\n",
        "    # If the only features to train on are \"duration_in_days\"\n",
        "    # train score = 0.6, test score = 0.6\n",
        "    # train_X = train_data.iloc[:, [5]]\n",
        "\n",
        "    test_y = test_data['state']\n",
        "    test_X = test_data.iloc[:, FEATURES_INDICES]\n",
        "    # test_X = test_data.iloc[:, [5]]\n",
        "    # examine_data(test_data)\n",
        "\n",
        "    LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(train_X, train_y)\n",
        "    pred_y = LR.predict(test_X)\n",
        "\n",
        "    evaluate(LR, test_X, test_y, pred_y)\n",
        "\n",
        "    '''\n",
        "    # Use score to evaluate\n",
        "    train_score = LR.score(train_X, train_y)\n",
        "    test_score = LR.score(test_X, test_y)\n",
        "    print(\"train score: {}\".format(train_score))\n",
        "    print(\"test score: {}\".format(test_score))\n",
        "    '''\n",
        "\n",
        "def sgd(train_data, test_data):\n",
        "    train_y = train_data['state']\n",
        "    train_X = train_data.iloc[:, FEATURES_INDICES]\n",
        "\n",
        "    test_y = test_data['state']\n",
        "    test_X = test_data.iloc[:, FEATURES_INDICES]\n",
        "\n",
        "    old_stdout = sys.stdout\n",
        "    sys.stdout = mystdout = StringIO()\n",
        "\n",
        "    # loss=\"log\" - logsitic regression\n",
        "    # shuffle=False, since the data has already been shuffled during pre-processing\n",
        "    SGD = SGDClassifier(loss=\"log\", penalty=\"l2\", early_stopping=True, max_iter=100, shuffle=False, verbose=1)\n",
        "    # SGD.partial_fit(train_X, train_y, classes=np.unique(train_y))\n",
        "    SGD.fit(train_X, train_y)\n",
        "    # new_weights = SGD.coef_\n",
        "    #print(\"Learned weights: {}\".format(SGD.coef_))\n",
        "    #print(\"Converged after {} iterations\".format(SGD.n_iter_))\n",
        "\n",
        "    sys.stdout = old_stdout\n",
        "    loss_history = mystdout.getvalue()\n",
        "    plot(loss_history)\n",
        "\n",
        "    pred_y = SGD.predict(test_X)\n",
        "    evaluate(SGD, test_X, test_y, pred_y)\n",
        "\n",
        "    cmap = plt.get_cmap('Blues')\n",
        "    plot_confusion_matrix(SGD, test_X, test_y, cmap=cmap)\n",
        "    plt.show()\n",
        "\n",
        "def plot(loss_history):\n",
        "    loss_list = []\n",
        "    for line in loss_history.split('\\n'):\n",
        "        if (len(line.split(\"loss: \")) == 1):\n",
        "            continue\n",
        "        loss_list.append(float(line.split(\"loss: \")[-1]))\n",
        "    plt.figure()\n",
        "    plt.plot(np.arange(len(loss_list)), loss_list)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Logistic Regression with Stochastic Gradient Descent\")\n",
        "    plt.show()\n",
        "\n",
        "'''\n",
        "def grid_search(train_data, test_data):\n",
        "    train_y = train_data['state']\n",
        "    train_X = train_data.iloc[:, FEATURES_INDICES]\n",
        "    #param_grid = {'alpha': np.power(10, np.arange(-4, 1, dtype=float))}\n",
        "    param_dist = {'alpha': loguniform(1e-4, 1e0)}\n",
        "\n",
        "    SGD = SGDClassifier(loss=\"log\", penalty=\"l2\", max_iter=350)\n",
        "    random_search = RandomizedSearchCV(SGD, param_distributions=param_dist,\n",
        "                                       n_iter=50)\n",
        "    random_search.fit(train_X, train_y)\n",
        "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
        "          \" parameter settings.\" % ((time() - start), 50))\n",
        "    report(random_search.cv_results_)\n",
        "'''\n",
        "\n",
        "# use mode to predict (always predict \"failed\")\n",
        "def baseline_mode(train_data, test_data):\n",
        "    # training data: 0 - 177863, 1 - 120645\n",
        "    # test data: 0 - 19856, 1 - 13311\n",
        "\n",
        "    # mode_freq = train_data['state'].value_counts().max()\n",
        "    # print(train_data['state'].value_counts())\n",
        "\n",
        "    # Get the mode (0, since mode is \"failed\")\n",
        "    mode = train_data['state'].value_counts().idxmax()\n",
        "\n",
        "    # How many times does 0 occur in the state column in test set?\n",
        "    count_in_test = (test_data.state == mode).sum()\n",
        "    # Total number of rows in test set\n",
        "    test_size = len(test_data.index)\n",
        "    accuracy = float(count_in_test / test_size)\n",
        "    f1_score = float(count_in_test/(count_in_test + 0.5*(test_size - count_in_test)))\n",
        "    print(\"accuracy={}, f1_score={}\".format(accuracy, f1_score))\n",
        "\n",
        "def baseline_single_feature(train_data, test_data):\n",
        "    train_y = train_data['state']\n",
        "\n",
        "    best_feature = None\n",
        "    best_score = 0\n",
        "    best_confusion_matrix = None\n",
        "    best_pred = None\n",
        "\n",
        "    test_y = test_data['state']\n",
        "    for feature, feature_idx in zip(FEATURES, FEATURES_INDICES):\n",
        "        train_X = train_data.iloc[:, [feature_idx]]\n",
        "        test_X = test_data.iloc[:, [feature_idx]]\n",
        "        LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(train_X, train_y)\n",
        "        pred_y = LR.predict(test_X)\n",
        "        score, confusion = evaluate(LR, test_X, test_y, pred_y, False)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_feature = feature\n",
        "            best_confusion_matrix = confusion\n",
        "            best_pred = pred_y\n",
        "    print_metrics(best_score, best_confusion_matrix, test_y, best_pred, best_feature)\n",
        "\n",
        "def examine_data(df):\n",
        "    print(\"\\n ------ Examining data... ------\")\n",
        "    # print(df.shape)\n",
        "    # print(df.head)\n",
        "    print(df['state'].value_counts())\n",
        "    print(\"------ Examination Done! ------\")\n",
        "\n",
        "def evaluate(model, test_X, test_y, pred_y, do_print=True):\n",
        "    '''\n",
        "    lbfgs: (18818+11094)/33167 = 0.90186\n",
        "    liblinear: (18860+11021)/33167 = 0.9009\n",
        "    newton-cg: (18884+10963)/33167 = 0.8999\n",
        "    '''\n",
        "    confusion = confusion_matrix(test_y, pred_y)\n",
        "    score = model.score(test_X, test_y)\n",
        "    if do_print:\n",
        "        print_metrics(score, confusion, test_y, pred_y)\n",
        "    return score, confusion\n",
        "\n",
        "def print_metrics(score, confusion_matrix, test_y, pred_y, feature=None):\n",
        "    if feature:\n",
        "        print(\"Best feature: {}\".format(feature))\n",
        "    print(confusion_matrix)\n",
        "    print(\"test score: {}\".format(score))\n",
        "    print(classification_report(test_y, pred_y, target_names=['0', '1']))\n",
        "\n",
        "\n",
        "# ============================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_data = None\n",
        "    test_data = None\n",
        "    if MODE == TransformMode.STANDARDIZE_SELECTED_COLUMNS:\n",
        "        train_data = pd.read_csv(STANDARDIZED_TRAIN_DATA_PATH)\n",
        "        test_data = pd.read_csv(STANDARDIZED_TEST_DATA_PATH)\n",
        "    elif MODE == TransformMode.SCALE_WITH_RANGE or MODE == TransformMode.SCALE_SELECTED_COLUMNS:\n",
        "        train_data = pd.read_csv(SCALED_TRAIN_DATA_PATH)\n",
        "        test_data = pd.read_csv(SCALED_TEST_DATA_PATH)\n",
        "    else:\n",
        "        #train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "        #test_data = pd.read_csv(TEST_DATA_PATH)\n",
        "        train_data = pd.read_csv(ONE_HOT_TRAIN_PATH_70)\n",
        "        test_data = pd.read_csv(ONE_HOT_TEST_PATH_70)\n",
        "\n",
        "    #logistic_regression(train_data, test_data)\n",
        "    #baseline_mode(train_data, test_data)\n",
        "    #baseline_single_feature(train_data, test_data)\n",
        "    sgd(train_data, test_data)\n",
        "    #grid_search(train_data, test_data)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Time taken: {}\".format(end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "id": "0LPk3uQCJwSK",
        "outputId": "d8bf4044-0ba0-4ece-d841-41c5ccd2183e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[52190  7047]\n",
            " [ 1708 38494]]\n",
            "test score: 0.9119560735727431\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.88      0.92     59237\n",
            "           1       0.85      0.96      0.90     40202\n",
            "\n",
            "    accuracy                           0.91     99439\n",
            "   macro avg       0.91      0.92      0.91     99439\n",
            "weighted avg       0.92      0.91      0.91     99439\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken: 2.3378212451934814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural network"
      ],
      "metadata": {
        "id": "jFHxzKhZMEEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier, Perceptron\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "TRAIN_DATA_PATH = \"../data/train.csv\"\n",
        "TEST_DATA_PATH = \"../data/test.csv\"\n",
        "\n",
        "TRAIN_STD_DATA_PATH = \"../data/train_standardized.csv\"\n",
        "TEST_STD_DATA_PATH = \"../data/test_standardized.csv\"\n",
        "\n",
        "DATA_PATH_1 = \"../data/test_99.csv\"\n",
        "DATA_PATH_5 = \"../data/test_95.csv\"\n",
        "\n",
        "ONE_HOT_TRAIN_PATH_70 = \"train_one_hot_70.csv\"\n",
        "ONE_HOT_TEST_PATH_70 = \"test_one_hot_70.csv\"\n",
        "\n",
        "#FEATURES_INDICES = [0,2,3,4,5]\n",
        "FEATURES_INDICES = list(range(1,41))\n",
        "\n",
        "def neural_network(train_data, test_data):\n",
        "    train_y = train_data['state']\n",
        "    train_X = train_data.iloc[:, FEATURES_INDICES]\n",
        "\n",
        "    test_y = test_data['state']\n",
        "    test_X = test_data.iloc[:, FEATURES_INDICES]\n",
        "\n",
        "    #search(train_X, train_y)\n",
        "    '''\n",
        "    MLP = MLPClassifier(activation='relu', hidden_layer_sizes=50,\n",
        "                    max_iter=500, alpha=1e-4, solver='adam', early_stopping=True,\n",
        "                    tol=1e-4, random_state=1, learning_rate_init=0.1)\n",
        "'''\n",
        "    MLP = MLPClassifier(hidden_layer_sizes=(40, 40, 40), alpha=0.05)\n",
        "    #MLP = MLPClassifier()\n",
        "    MLP.fit(train_X, train_y)\n",
        "    print(\"Ran for {} iterations\".format(MLP.n_iter_))\n",
        "\n",
        "    pred_y = MLP.predict(test_X)\n",
        "    evaluate(MLP, test_X, test_y, pred_y)\n",
        "\n",
        "\n",
        "def search(train_X, train_y):\n",
        "    MLP = MLPClassifier()\n",
        "    parameter_space = {\n",
        "        'hidden_layer_sizes': [(15, 15, 15), (50, 50, 50), (80, 80, 80), (100, 100, 100)],\n",
        "        #'activation': ['relu'],\n",
        "        #'solver': ['adam'],\n",
        "        #'learning_rate': ['constant', 'adaptive']\n",
        "        'alpha': [0.0001, 0.05, 0.001, 0.01]\n",
        "    }\n",
        "    gs = GridSearchCV(estimator=MLP,\n",
        "                      param_grid=parameter_space,\n",
        "                      n_jobs=-1,\n",
        "                      scoring='accuracy')\n",
        "    gs.fit(train_X, train_y)\n",
        "    print(\"Best score from grid search: {}\".format(gs.best_score_))\n",
        "    print(\"Best parameters from grid search: {}\".format(gs.best_params_))\n",
        "\n",
        "def evaluate(model, test_X, test_y, pred_y, do_print=True):\n",
        "    confusion = confusion_matrix(test_y, pred_y)\n",
        "    score = model.score(test_X, test_y)\n",
        "    if do_print:\n",
        "        print_metrics(score, confusion, test_y, pred_y)\n",
        "    return score, confusion\n",
        "\n",
        "def print_metrics(score, confusion_matrix, test_y, pred_y, feature=None):\n",
        "    if feature:\n",
        "        print(\"Best feature: {}\".format(feature))\n",
        "    print(confusion_matrix)\n",
        "    print(\"test score: {}\".format(score))\n",
        "    print(classification_report(test_y, pred_y, target_names=['0', '1']))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "\n",
        "    USE_SMALL = False\n",
        "    '''\n",
        "    if USE_SMALL:\n",
        "        train_data = pd.read_csv(DATA_PATH_5)\n",
        "        test_data = pd.read_csv(DATA_PATH_1)\n",
        "    else:\n",
        "        train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "        test_data = pd.read_csv(TEST_DATA_PATH)\n",
        "    '''\n",
        "    # train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "    # test_data = pd.read_csv(TEST_DATA_PATH)\n",
        "    train_data = pd.read_csv(ONE_HOT_TRAIN_PATH_70)\n",
        "    test_data = pd.read_csv(ONE_HOT_TEST_PATH_70)\n",
        "\n",
        "    neural_network(train_data, test_data)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Time taken: {}\".format(end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQtOUF6YK1SE",
        "outputId": "f7f19fba-1407-4ec8-fe4b-65a9a71a322b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ran for 24 iterations\n",
            "[[55317  3920]\n",
            " [ 3384 36818]]\n",
            "test score: 0.9265479339092307\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.94     59237\n",
            "           1       0.90      0.92      0.91     40202\n",
            "\n",
            "    accuracy                           0.93     99439\n",
            "   macro avg       0.92      0.92      0.92     99439\n",
            "weighted avg       0.93      0.93      0.93     99439\n",
            "\n",
            "Time taken: 88.69908690452576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perceptron"
      ],
      "metadata": {
        "id": "cbcoqqbVM-3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "TRAIN_DATA_PATH = \"../data/train.csv\"\n",
        "TEST_DATA_PATH = \"../data/test.csv\"\n",
        "\n",
        "ONE_HOT_TRAIN_PATH_70 = \"train_one_hot_70.csv\"\n",
        "ONE_HOT_TEST_PATH_70 = \"test_one_hot_70.csv\"\n",
        "\n",
        "#FEATURES_INDICES = [0,2,3,4,5]\n",
        "FEATURES_INDICES = list(range(1,41))\n",
        "\n",
        "def perceptron(train_data, test_data):\n",
        "    train_y = train_data['state']\n",
        "    train_X = train_data.iloc[:, FEATURES_INDICES]\n",
        "\n",
        "    test_y = test_data['state']\n",
        "    test_X = test_data.iloc[:, FEATURES_INDICES]\n",
        "\n",
        "    ppn = Perceptron(penalty=\"l2\", n_jobs=-1, early_stopping=True)\n",
        "    ppn.fit(train_X, train_y)\n",
        "\n",
        "    pred_y = ppn.predict(test_X)\n",
        "    evaluate(ppn, test_X, test_y, pred_y)\n",
        "\n",
        "def evaluate(model, test_X, test_y, pred_y, do_print=True):\n",
        "    confusion = confusion_matrix(test_y, pred_y)\n",
        "    score = model.score(test_X, test_y)\n",
        "    if do_print:\n",
        "        print_metrics(score, confusion, test_y, pred_y)\n",
        "    return score, confusion\n",
        "\n",
        "def print_metrics(score, confusion_matrix, test_y, pred_y, feature=None):\n",
        "    if feature:\n",
        "        print(\"Best feature: {}\".format(feature))\n",
        "    print(confusion_matrix)\n",
        "    print(\"test score: {}\".format(score))\n",
        "    print(classification_report(test_y, pred_y, target_names=['0', '1']))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "\n",
        "    #train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "    #test_data = pd.read_csv(TEST_DATA_PATH)\n",
        "    train_data = pd.read_csv(ONE_HOT_TRAIN_PATH_70)\n",
        "    test_data = pd.read_csv(ONE_HOT_TEST_PATH_70)\n",
        "\n",
        "    perceptron(train_data, test_data)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Time taken: {}\".format(end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJc4U_BwMS0F",
        "outputId": "3d74c63e-87cd-4d86-bf0a-6c4387b80c0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[53720  5517]\n",
            " [ 7550 32652]]\n",
            "test score: 0.8685928056396384\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.91      0.89     59237\n",
            "           1       0.86      0.81      0.83     40202\n",
            "\n",
            "    accuracy                           0.87     99439\n",
            "   macro avg       0.87      0.86      0.86     99439\n",
            "weighted avg       0.87      0.87      0.87     99439\n",
            "\n",
            "Time taken: 4.103998422622681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ada-boost"
      ],
      "metadata": {
        "id": "xxvgyX8eNx5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier, Perceptron\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "TRAIN_DATA_PATH = \"../data/train.csv\"\n",
        "TEST_DATA_PATH = \"../data/test.csv\"\n",
        "\n",
        "ONE_HOT_TRAIN_PATH_70 = \"train_one_hot_70.csv\"\n",
        "ONE_HOT_TEST_PATH_70 = \"test_one_hot_70.csv\"\n",
        "\n",
        "#FEATURES_INDICES = [0,2,3,4,5]\n",
        "FEATURES_INDICES = list(range(1,41))\n",
        "\n",
        "def ada_boost(train_data, test_data):\n",
        "    train_y = train_data['state']\n",
        "    train_X = train_data.iloc[:, FEATURES_INDICES]\n",
        "\n",
        "    test_y = test_data['state']\n",
        "    test_X = test_data.iloc[:, FEATURES_INDICES]\n",
        "\n",
        "    #search(train_X, train_y)\n",
        "    dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n",
        "    ADA = AdaBoostClassifier(learning_rate=0.1, n_estimators=100, base_estimator=dt)\n",
        "    ADA.fit(train_X, train_y)\n",
        "\n",
        "    pred_y = ADA.predict(test_X)\n",
        "    evaluate(ADA, test_X, test_y, pred_y)\n",
        "\n",
        "def search(train_X, train_y):\n",
        "    param_depth=[5, 10, 15]\n",
        "    for depth in param_depth:\n",
        "        param_n_estimators = [20, 50, 80, 100]\n",
        "        param_learning_rates = [0.1, 0.3, 0.5, 0.75, 1]\n",
        "        param_grid = [{'n_estimators': param_n_estimators,\n",
        "                       'learning_rate': param_learning_rates\n",
        "                      }]\n",
        "        dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=depth)\n",
        "        gs = GridSearchCV(estimator=AdaBoostClassifier(base_estimator=dt),\n",
        "                          param_grid=param_grid,\n",
        "                          scoring='accuracy')\n",
        "        gs.fit(train_X, train_y)\n",
        "        print(\"====== Stats for depth={}\".format(depth))\n",
        "        print(\"Best score from grid search: {}\".format(gs.best_score_))\n",
        "        print(\"Best parameters from grid search: {}\\n\".format(gs.best_params_))\n",
        "\n",
        "\n",
        "def evaluate(model, test_X, test_y, pred_y, do_print=True):\n",
        "    confusion = confusion_matrix(test_y, pred_y)\n",
        "    score = model.score(test_X, test_y)\n",
        "    if do_print:\n",
        "        print_metrics(score, confusion, test_y, pred_y)\n",
        "    return score, confusion\n",
        "\n",
        "def print_metrics(score, confusion_matrix, test_y, pred_y, feature=None):\n",
        "    if feature:\n",
        "        print(\"Best feature: {}\".format(feature))\n",
        "    print(confusion_matrix)\n",
        "    print(\"test score: {}\".format(score))\n",
        "    print(classification_report(test_y, pred_y, target_names=['0', '1']))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "\n",
        "    #train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "    #test_data = pd.read_csv(TEST_DATA_PATH)\n",
        "    train_data = pd.read_csv(ONE_HOT_TRAIN_PATH_70)\n",
        "    test_data = pd.read_csv(ONE_HOT_TEST_PATH_70)\n",
        "\n",
        "    ada_boost(train_data, test_data)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Time taken: {}\".format(end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrYktJ2kNCie",
        "outputId": "8c16c721-b466-4aea-f8c8-b54186aed9f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[55496  3741]\n",
            " [ 2932 37270]]\n",
            "test score: 0.932893532718551\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94     59237\n",
            "           1       0.91      0.93      0.92     40202\n",
            "\n",
            "    accuracy                           0.93     99439\n",
            "   macro avg       0.93      0.93      0.93     99439\n",
            "weighted avg       0.93      0.93      0.93     99439\n",
            "\n",
            "Time taken: 72.98464012145996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bagging"
      ],
      "metadata": {
        "id": "HIsjS6boOTfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier, Perceptron\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "TRAIN_DATA_PATH = \"../data/train.csv\"\n",
        "TEST_DATA_PATH = \"../data/test.csv\"\n",
        "\n",
        "ONE_HOT_TRAIN_PATH_70 = \"train_one_hot_70.csv\"\n",
        "ONE_HOT_TEST_PATH_70 = \"test_one_hot_70.csv\"\n",
        "\n",
        "#FEATURES_INDICES = [0,2,3,4,5]\n",
        "FEATURES_INDICES = list(range(1,41))\n",
        "\n",
        "def bagging(train_data, test_data):\n",
        "    train_y = train_data['state']\n",
        "    train_X = train_data.iloc[:, FEATURES_INDICES]\n",
        "\n",
        "    test_y = test_data['state']\n",
        "    test_X = test_data.iloc[:, FEATURES_INDICES]\n",
        "\n",
        "    KNN = KNeighborsClassifier(n_neighbors=15)\n",
        "    DT = DecisionTreeClassifier(criterion=\"entropy\", max_depth=10)\n",
        "    # Got \"ZeroDivisionError: Weights sum to zero, can't be normalized\" for both perceptron and SGD\n",
        "    #PPN = Perceptron(penalty=\"l2\", n_jobs=-1, early_stopping=True)\n",
        "    #SGD = SGDClassifier(loss=\"log\", penalty=\"l2\", early_stopping=True, shuffle=False, verbose=0)\n",
        "\n",
        "    bag = BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion=\"entropy\", max_depth=10),\n",
        "                            n_estimators=14)\n",
        "    bag.fit(train_X, train_y)\n",
        "\n",
        "    pred_y = bag.predict(test_X)\n",
        "    evaluate(bag, test_X, test_y, pred_y)\n",
        "\n",
        "\n",
        "def evaluate(model, test_X, test_y, pred_y, do_print=True):\n",
        "    confusion = confusion_matrix(test_y, pred_y)\n",
        "    score = model.score(test_X, test_y)\n",
        "    if do_print:\n",
        "        print_metrics(score, confusion, test_y, pred_y)\n",
        "    return score, confusion\n",
        "\n",
        "def print_metrics(score, confusion_matrix, test_y, pred_y, feature=None):\n",
        "    if feature:\n",
        "        print(\"Best feature: {}\".format(feature))\n",
        "    print(confusion_matrix)\n",
        "    print(\"test score: {}\".format(score))\n",
        "    print(classification_report(test_y, pred_y, target_names=['0', '1']))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "\n",
        "    #train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "    #test_data = pd.read_csv(TEST_DATA_PATH)\n",
        "    train_data = pd.read_csv(ONE_HOT_TRAIN_PATH_70)\n",
        "    test_data = pd.read_csv(ONE_HOT_TEST_PATH_70)\n",
        "\n",
        "    bagging(train_data, test_data)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Time taken: {}\".format(end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxxaTDCIN0oU",
        "outputId": "744bc67d-12a3-4865-d297-6880d40ac753"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[55507  3730]\n",
            " [ 3086 37116]]\n",
            "test score: 0.931455465159545\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94     59237\n",
            "           1       0.91      0.92      0.92     40202\n",
            "\n",
            "    accuracy                           0.93     99439\n",
            "   macro avg       0.93      0.93      0.93     99439\n",
            "weighted avg       0.93      0.93      0.93     99439\n",
            "\n",
            "Time taken: 15.29805874824524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient boost"
      ],
      "metadata": {
        "id": "_9oVSlQCOr35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "TRAIN_DATA_PATH = \"../data/train.csv\"\n",
        "TEST_DATA_PATH = \"../data/test.csv\"\n",
        "\n",
        "TRAIN_STD_DATA_PATH = \"../data/train_standardized.csv\"\n",
        "TEST_STD_DATA_PATH = \"../data/test_standardized.csv\"\n",
        "\n",
        "ONE_HOT_TRAIN_PATH_70 = \"train_one_hot_70.csv\"\n",
        "ONE_HOT_TEST_PATH_70 = \"test_one_hot_70.csv\"\n",
        "\n",
        "#FEATURES_INDICES = [0,2,3,4,5]\n",
        "FEATURES_INDICES = list(range(1,41))\n",
        "\n",
        "def gradient_boost(train_data, test_data):\n",
        "    train_y = train_data['state']\n",
        "    train_X = train_data.iloc[:, FEATURES_INDICES]\n",
        "\n",
        "    test_y = test_data['state']\n",
        "    test_X = test_data.iloc[:, FEATURES_INDICES]\n",
        "\n",
        "    #search(train_X, train_y)\n",
        "    #search_xgboost(train_X, train_y)\n",
        "    gd = HistGradientBoostingClassifier(loss='auto', max_bins=200, max_depth=10, max_leaf_nodes=35)\n",
        "\n",
        "    #gd = XGBClassifier()\n",
        "    gd.fit(train_X, train_y)\n",
        "\n",
        "    pred_y = gd.predict(test_X)\n",
        "    evaluate(gd, test_X, test_y, pred_y)\n",
        "\n",
        "\n",
        "def search(train_X, train_y):\n",
        "    param_learning_rates = [0.1, 0.3, 0.5]\n",
        "    param_max_leaf_nodes = [31, 35, 40]\n",
        "    param_max_bins = [150, 200, 250]\n",
        "    param_max_depth = [5, 7, 10]\n",
        "    #param_min_samples_leaf = [25, 30, 35]\n",
        "    #param_gamma = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0]\n",
        "    param_grid = [{#'learning_rate': param_learning_rates,\n",
        "                   'max_leaf_nodes': param_max_leaf_nodes,\n",
        "                   'max_bins':param_max_bins,\n",
        "                   'max_depth': param_max_depth\n",
        "                   #'min_samples_leaf': param_min_samples_leaf\n",
        "                   }]\n",
        "    gs = GridSearchCV(estimator=HistGradientBoostingClassifier(loss='binary_crossentropy', learning_rate=0.1),\n",
        "                      param_grid=param_grid,\n",
        "                      n_jobs=-1,\n",
        "                      scoring='accuracy')\n",
        "\n",
        "    gs.fit(train_X, train_y)\n",
        "    print(\"Best score from grid search: {}\".format(gs.best_score_))\n",
        "    print(\"Best parameters from grid search: {}\".format(gs.best_params_))\n",
        "\n",
        "def search_xgboost(train_X, train_y):\n",
        "    param_eta = [0.01, 0.1, 0.2]\n",
        "    param_max_depth = [5, 8, 10]\n",
        "    param_grid = [{  'eta': param_eta,\n",
        "                     'max_depth': param_max_depth\n",
        "    }]\n",
        "    XGB = XGBClassifier()\n",
        "    gs = GridSearchCV(estimator=XGB,\n",
        "                      param_grid=param_grid,\n",
        "                      n_jobs=-1,\n",
        "                      scoring='accuracy')\n",
        "\n",
        "    gs.fit(train_X, train_y)\n",
        "    print(\"Best score from grid search: {}\".format(gs.best_score_))\n",
        "    print(\"Best parameters from grid search: {}\".format(gs.best_params_))\n",
        "\n",
        "def evaluate(model, test_X, test_y, pred_y, do_print=True):\n",
        "    confusion = confusion_matrix(test_y, pred_y)\n",
        "    score = model.score(test_X, test_y)\n",
        "    if do_print:\n",
        "        print_metrics(score, confusion, test_y, pred_y)\n",
        "    return score, confusion\n",
        "\n",
        "def print_metrics(score, confusion_matrix, test_y, pred_y, feature=None):\n",
        "    if feature:\n",
        "        print(\"Best feature: {}\".format(feature))\n",
        "    print(confusion_matrix)\n",
        "    TP = confusion_matrix[0][0]\n",
        "    FP = confusion_matrix[0][1]\n",
        "    FN = confusion_matrix[1][0]\n",
        "    f1 = float(TP/(TP+0.5*(FP+FN)))\n",
        "    print(\"test score: {}\".format(score))\n",
        "    print(\"F1 score: {}\".format(f1))\n",
        "    print(classification_report(test_y, pred_y, target_names=['0', '1']))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "\n",
        "    # train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "    # test_data = pd.read_csv(TEST_DATA_PATH)\n",
        "    train_data = pd.read_csv(ONE_HOT_TRAIN_PATH_70)\n",
        "    test_data = pd.read_csv(ONE_HOT_TEST_PATH_70)\n",
        "\n",
        "    gradient_boost(train_data, test_data)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Time taken: {}\".format(end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxJw2WH6OVtL",
        "outputId": "144061b0-b3e3-4a37-d105-fb985b925498"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:17: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  \"Since version 1.0, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[55636  3601]\n",
            " [ 3006 37196]]\n",
            "test score: 0.9335572562073231\n",
            "F1 score: 0.9439510006023125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94     59237\n",
            "           1       0.91      0.93      0.92     40202\n",
            "\n",
            "    accuracy                           0.93     99439\n",
            "   macro avg       0.93      0.93      0.93     99439\n",
            "weighted avg       0.93      0.93      0.93     99439\n",
            "\n",
            "Time taken: 15.608320474624634\n"
          ]
        }
      ]
    }
  ]
}